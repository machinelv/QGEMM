{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import multiprocessing\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "import yaml\n",
    "\n",
    "import torch.cuda\n",
    "\n",
    "from utils import set_seed\n",
    "try:\n",
    "    from task import TestSpec\n",
    "except ImportError:\n",
    "    TestSpec = dict\n",
    "\n",
    "from reference import check_implementation, generate_input\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TestCase:\n",
    "    args: dict\n",
    "    spec: str\n",
    "    memory_usage: Optional[float] = None\n",
    "    FLOPs: Optional[int] = None\n",
    "\n",
    "def _combine(a: int, b: int) -> int:\n",
    "    # combine two integers into one:\n",
    "    # we need this to generate a secret seed based on the test-level seed and\n",
    "    # the global secret seed.\n",
    "    # the test-level seeds are public knowledge, and typically relatively small numbers,\n",
    "    # so we need to make sure they don't provide any useful info for the full seed.\n",
    "    # This Cantor construction ensures that if the secret seed is a large number,\n",
    "    # then so is the overall seed.\n",
    "    return int(a + (a+b)*(a+b+1)//2)\n",
    "\n",
    "\n",
    "def get_test_cases(file_name: str, data_type: str, seed: Optional[int]) -> list[TestCase]:\n",
    "    try:\n",
    "        with open(file_name, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "    except Exception as E:\n",
    "        print(f\"Could not open test file`{file_name}`: {E}\", file=sys.stderr)\n",
    "        exit(113)\n",
    "\n",
    "    tests_data = data.get(data_type, None)\n",
    "    if tests_data is None:\n",
    "        print(f\"Could not find test data for type `{data_type}` in file `{file_name}`\", file=sys.stderr)\n",
    "        exit(113)\n",
    "\n",
    "    tests = []\n",
    "    for data in tests_data:\n",
    "        memory_usage = (data['m'] * data['n'] + data['k'] * data['n'] + data['k'] * data['m']) * 2 / 1024 / 1024\n",
    "        FLOPs = (data['m'] * data['n'] * data['k']) * 2\n",
    "        tests.append(TestCase(spec=str(data), args=data, memory_usage=memory_usage, FLOPs=FLOPs))\n",
    "\n",
    "    if seed is not None:\n",
    "        for test in tests:\n",
    "            if \"seed\" in test.args:\n",
    "                test.args[\"seed\"] = _combine(test.args[\"seed\"], seed)\n",
    "\n",
    "    return tests\n",
    "\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Stats:\n",
    "    runs: int\n",
    "    mean: float\n",
    "    std: float\n",
    "    err: float\n",
    "    best: float\n",
    "    worst: float\n",
    "\n",
    "def calculate_stats(durations: list[int]):\n",
    "    \"\"\"\n",
    "    Calculate statistical data from a list of durations.\n",
    "\n",
    "    @param durations: A list of durations in nanoseconds.\n",
    "    @return: A Stats object containing the number of runs, mean, standard deviation, error, best, and worst durations.\n",
    "    \"\"\"\n",
    "    runs = len(durations)\n",
    "    total = sum(durations)\n",
    "    best = min(durations)\n",
    "    worst = max(durations)\n",
    "\n",
    "    avg = total / runs\n",
    "    variance = sum(map(lambda x: (x - avg)**2, durations))\n",
    "    std = math.sqrt(variance / (runs - 1))\n",
    "    err = std / math.sqrt(runs)\n",
    "\n",
    "    return Stats(runs=runs, mean=avg, std=std, err=err, best=float(best),\n",
    "                 worst=float(worst))\n",
    "\n",
    "def _clone_data(data):\n",
    "    \"\"\"\n",
    "    Recursively goes through data and clones all tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(data, tuple):\n",
    "        return tuple(_clone_data(x) for x in data)\n",
    "    elif isinstance(data, list):\n",
    "        return [_clone_data(x) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        return {k: _clone_data(v) for k, v in data.items()}\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.clone()\n",
    "    else:\n",
    "        return data\n",
    "        \n",
    "def wrap_check_implementation(data, submission_output):\n",
    "    # Old version returned just a single string, new version\n",
    "    # returns (bool, str); this function ensures compatibility with old\n",
    "    # problem definitions.\n",
    "    result = check_implementation(data, submission_output)\n",
    "    if isinstance(result, tuple):\n",
    "        return result\n",
    "    else:\n",
    "        return not bool(result), result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478eab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CUDA source file and the Python submission file\n",
    "cuda_file_path = Path('./csrc_kernel/gemm_fp8_v1.hpp')\n",
    "submission_file_path = Path('./hip_submission.py') # Assuming hip_submission.py is in the current directory\n",
    "\n",
    "# Check if the CUDA source file exists\n",
    "if not cuda_file_path.exists():\n",
    "    print(f\"Error: CUDA source file not found at {cuda_file_path}\", file=sys.stderr)\n",
    "else:\n",
    "    # Read the content of the CUDA source file\n",
    "    try:\n",
    "        with open(cuda_file_path, 'r') as f:\n",
    "            cuda_code = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CUDA source file {cuda_file_path}: {e}\", file=sys.stderr)\n",
    "        cuda_code = None\n",
    "\n",
    "    if cuda_code is not None:\n",
    "        # Prepare the new CUDA_SRC variable assignment string\n",
    "        # We need to represent the multiline CUDA code as a raw string literal in Python\n",
    "        new_src_assignment = f\"CUDA_SRC = r'''\\n{cuda_code}\\n'''\"\n",
    "\n",
    "        # Check if the submission file exists\n",
    "        if not submission_file_path.exists():\n",
    "            print(f\"Warning: Submission file {submission_file_path} not found. Creating it with the CUDA_SRC variable.\", file=sys.stderr)\n",
    "            try:\n",
    "                with open(submission_file_path, 'w') as f:\n",
    "                    f.write(new_src_assignment + \"\\n\")\n",
    "                print(f\"Successfully created {submission_file_path} and wrote CUDA_SRC.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating or writing to {submission_file_path}: {e}\", file=sys.stderr)\n",
    "        else:\n",
    "            # Read the content of the Python submission file\n",
    "            try:\n",
    "                with open(submission_file_path, 'r') as f:\n",
    "                    submission_code_lines = f.readlines()\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading submission file {submission_file_path}: {e}\", file=sys.stderr)\n",
    "                submission_code_lines = None\n",
    "\n",
    "            if submission_code_lines is not None:\n",
    "                # Find and replace the CUDA_SRC variable assignment\n",
    "                # This regex looks for CUDA_SRC = r'''...''' or CUDA_SRC = '''...''' or CUDA_SRC = \"...\" etc.\n",
    "                # and handles multi-line strings.\n",
    "                \n",
    "                # A simpler approach for this specific problem might be to find the line starting with \"CUDA_SRC =\"\n",
    "                # and replace it and subsequent lines if it's a multi-line string,\n",
    "                # or just replace that line if it's a single line string.\n",
    "                # For robustness, we'll try to replace a block.\n",
    "\n",
    "                new_submission_code = []\n",
    "                src_found = False\n",
    "                in_src_block = False\n",
    "\n",
    "                # Try to find an existing CUDA_SRC assignment\n",
    "                # This pattern is very basic and might need adjustment based on actual CUDA_SRC format\n",
    "                src_pattern = re.compile(r\"^\\s*CUDA_SRC\\s*=\\s*r?['\\\"]{3}.*?['\\\"]{3}\\s*$\", re.DOTALL | re.MULTILINE)\n",
    "                \n",
    "                try:\n",
    "                    with open(submission_file_path, 'r') as f:\n",
    "                        submission_content = f.read()\n",
    "                    \n",
    "                    if src_pattern.search(submission_content):\n",
    "                        # If a complex multi-line CUDA_SRC string is found, replace it\n",
    "                        updated_submission_content = src_pattern.sub(new_src_assignment, submission_content, count=1)\n",
    "                    else:\n",
    "                        # If not found, or if it's a simpler assignment, try a line-based replacement\n",
    "                        # This is a fallback and might be less robust for complex existing CUDA_SRC assignments\n",
    "                        temp_lines = []\n",
    "                        replaced = False\n",
    "                        for line in submission_code_lines:\n",
    "                            if line.strip().startswith(\"CUDA_SRC =\") and not replaced:\n",
    "                                temp_lines.append(new_src_assignment + \"\\n\")\n",
    "                                replaced = True\n",
    "                                # Skip lines if it was a multiline string; this part is tricky without knowing the exact old format\n",
    "                                # For simplicity, we assume the old CUDA_SRC was either single line or we are just prepending/replacing.\n",
    "                            elif replaced and (line.strip().startswith(\"'''\") or line.strip().startswith('\"\"\"')): # Heuristic to skip old multiline end\n",
    "                                if \"CUDA_SRC =\" not in new_src_assignment: # only skip if we are truly replacing a block\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    temp_lines.append(line)\n",
    "                            elif not replaced or not (line.strip().startswith(\"'''\") or line.strip().startswith('\"\"\"')):\n",
    "                                temp_lines.append(line)\n",
    "                        \n",
    "                        if not replaced: # If CUDA_SRC = was not found at all, prepend it\n",
    "                            updated_submission_content = new_src_assignment + \"\\n\" + \"\".join(submission_code_lines)\n",
    "                        else:\n",
    "                            updated_submission_content = \"\".join(temp_lines)\n",
    "                            \n",
    "                    with open(submission_file_path, 'w') as f:\n",
    "                        f.write(updated_submission_content)\n",
    "                    print(f\"Successfully updated CUDA_SRC in {submission_file_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing or writing to submission file {submission_file_path}: {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff58c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _run_single_test(test: TestCase):\n",
    "    \"\"\"\n",
    "    Runs a single test case. Do not call directly\n",
    "    \"\"\"\n",
    "    from hip_submission import custom_kernel\n",
    "\n",
    "    data = generate_input(**test.args)\n",
    "    start_time = time.time()\n",
    "    torch.cuda.synchronize()\n",
    "    submission_output =  custom_kernel(_clone_data(data))\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    duration = float((end_time - start_time) * 1e3)  # convert to nanoseconds\n",
    "    good, message = wrap_check_implementation(data, submission_output)\n",
    "    return good, message, duration\n",
    "\n",
    "def run_single_test(pool: multiprocessing.Pool, test: TestCase):\n",
    "    \"\"\"\n",
    "    Runs a single test in another process.\n",
    "    \"\"\"\n",
    "    return pool.apply(_run_single_test, (test,))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "set_seed(seed or 42)\n",
    "tests_data = get_test_cases('./task.yml', 'tests', seed)\n",
    "\n",
    "# The 'multiprocessing' module is already imported in cell 0.\n",
    "# The 'time' module is already imported in cell 0.\n",
    "\n",
    "# It's good practice to initialize a flag for overall test status.\n",
    "passed = True \n",
    "total_duration = 0.0\n",
    "for idx, test in enumerate(tests_data):\n",
    "    print(f\"test.{idx}.name\", test.spec)\n",
    "    good, message, duration = _run_single_test(test)\n",
    "    total_duration += duration\n",
    "    if not good:\n",
    "        print(f\"test.{idx}.status\", \"fail\")\n",
    "        print(f\"test.{idx}.error\", message)\n",
    "        passed = False\n",
    "    else:\n",
    "        print(f\"test.{idx}.status\", \"pass\")\n",
    "        print(f\"test.{idx}.duration {duration:.4f}ms\")\n",
    "        print(f\"test.{idx}.TFLOPS {test.FLOPs/duration*1e-9:.4f}\")\n",
    "        if message:\n",
    "            print(f\"test.{idx}.message\", f\"{message}\")\n",
    "print(f\"test.total_duration {total_duration:.4f}ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab51155",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed or 42)\n",
    "tests_data = get_test_cases('./task.yml', 'benchmarks', seed)\n",
    "\n",
    "# import multiprocessing\n",
    "# mp_context = multiprocessing.get_context('spawn')\n",
    "# with mp_context.Pool(1) as pool:\n",
    "#     for idx, test in enumerate(tests_data):\n",
    "#         good, message = run_single_test(pool, test)\n",
    "# import time\n",
    "\n",
    "\n",
    "total_duration = 0\n",
    "for idx, test in enumerate(tests_data):\n",
    "    print(f\"test.{idx}.name\", test.spec)\n",
    "    good, message, duration = _run_single_test(test)\n",
    "    total_duration += duration\n",
    "    if not good:\n",
    "        print(f\"test.{idx}.status\", \"fail\")\n",
    "        print(f\"test.{idx}.error\", message)\n",
    "        passed = False\n",
    "    else:\n",
    "        print(f\"test.{idx}.status\", \"pass\")\n",
    "        print(f\"test.{idx}.duration {duration:.4f}ms\")\n",
    "        print(f\"test.{idx}.TFLOPS {test.FLOPs/duration*1e-9:.4f}\")\n",
    "        if message:\n",
    "            print(f\"test.{idx}.message\", f\"{message}\")\n",
    "print(f\"test.total_duration {total_duration:.4f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05aa43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[0, 1, 2, 3], [4, 5, 6, 7]])\n",
    "\n",
    "offs_k = np.arange(0, 4)\n",
    "k = offs_k[:,None]\n",
    "offs_n = np.arange(0, 2)\n",
    "n = offs_n[None,:]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
