{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21822860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import multiprocessing\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "import yaml\n",
    "\n",
    "import torch.cuda\n",
    "\n",
    "from utils import set_seed\n",
    "try:\n",
    "    from task import TestSpec\n",
    "except ImportError:\n",
    "    TestSpec = dict\n",
    "\n",
    "from reference import check_implementation, generate_input\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TestCase:\n",
    "    args: dict\n",
    "    spec: str\n",
    "    memory_usage: Optional[float] = None\n",
    "    FLOPs: Optional[int] = None\n",
    "\n",
    "def _combine(a: int, b: int) -> int:\n",
    "    # combine two integers into one:\n",
    "    # we need this to generate a secret seed based on the test-level seed and\n",
    "    # the global secret seed.\n",
    "    # the test-level seeds are public knowledge, and typically relatively small numbers,\n",
    "    # so we need to make sure they don't provide any useful info for the full seed.\n",
    "    # This Cantor construction ensures that if the secret seed is a large number,\n",
    "    # then so is the overall seed.\n",
    "    return int(a + (a+b)*(a+b+1)//2)\n",
    "\n",
    "\n",
    "def get_test_cases(file_name: str, data_type: str, seed: Optional[int]) -> list[TestCase]:\n",
    "    try:\n",
    "        with open(file_name, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "    except Exception as E:\n",
    "        print(f\"Could not open test file`{file_name}`: {E}\", file=sys.stderr)\n",
    "        exit(113)\n",
    "\n",
    "    tests_data = data.get(data_type, None)\n",
    "    if tests_data is None:\n",
    "        print(f\"Could not find test data for type `{data_type}` in file `{file_name}`\", file=sys.stderr)\n",
    "        exit(113)\n",
    "\n",
    "    tests = []\n",
    "    for data in tests_data:\n",
    "        memory_usage = (data['m'] * data['n'] + data['k'] * data['n'] + data['k'] * data['m']) * 2 / 1024 / 1024\n",
    "        FLOPs = (data['m'] * data['n'] * data['k']) * 2\n",
    "        tests.append(TestCase(spec=str(data), args=data, memory_usage=memory_usage, FLOPs=FLOPs))\n",
    "\n",
    "    if seed is not None:\n",
    "        for test in tests:\n",
    "            if \"seed\" in test.args:\n",
    "                test.args[\"seed\"] = _combine(test.args[\"seed\"], seed)\n",
    "\n",
    "    return tests\n",
    "\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Stats:\n",
    "    runs: int\n",
    "    mean: float\n",
    "    std: float\n",
    "    err: float\n",
    "    best: float\n",
    "    worst: float\n",
    "\n",
    "def calculate_stats(durations: list[int]):\n",
    "    \"\"\"\n",
    "    Calculate statistical data from a list of durations.\n",
    "\n",
    "    @param durations: A list of durations in nanoseconds.\n",
    "    @return: A Stats object containing the number of runs, mean, standard deviation, error, best, and worst durations.\n",
    "    \"\"\"\n",
    "    runs = len(durations)\n",
    "    total = sum(durations)\n",
    "    best = min(durations)\n",
    "    worst = max(durations)\n",
    "\n",
    "    avg = total / runs\n",
    "    variance = sum(map(lambda x: (x - avg)**2, durations))\n",
    "    std = math.sqrt(variance / (runs - 1))\n",
    "    err = std / math.sqrt(runs)\n",
    "\n",
    "    return Stats(runs=runs, mean=avg, std=std, err=err, best=float(best),\n",
    "                 worst=float(worst))\n",
    "\n",
    "def _clone_data(data):\n",
    "    \"\"\"\n",
    "    Recursively goes through data and clones all tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(data, tuple):\n",
    "        return tuple(_clone_data(x) for x in data)\n",
    "    elif isinstance(data, list):\n",
    "        return [_clone_data(x) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        return {k: _clone_data(v) for k, v in data.items()}\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.clone()\n",
    "    else:\n",
    "        return data\n",
    "        \n",
    "def wrap_check_implementation(data, submission_output):\n",
    "    # Old version returned just a single string, new version\n",
    "    # returns (bool, str); this function ensures compatibility with old\n",
    "    # problem definitions.\n",
    "    result = check_implementation(data, submission_output)\n",
    "    if isinstance(result, tuple):\n",
    "        return result\n",
    "    else:\n",
    "        return not bool(result), result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4a573",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
